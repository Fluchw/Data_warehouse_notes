## 1. 通用脚本
```shell
cd /home/wuss/bin
vim xcall.sh

#!/bin/bash
if [ $# -lt 1 ]
then
 echo "No Args Error!!!!"
 exit;
fi

for i in hadoop102 hadoop103 hadoop104
do
  echo "=================> $i <================="
  ssh $i "$*"
done


chmod 777 xcall.sh
```
## 2. 查看脚本
```shell
cd /home/wuss/bin
vim jpsall

#!/bin/bash
for host in hadoop102 hadoop103 hadoop104 
do 
	echo =============== $host =============== 
	ssh $host jps
done

chmod 777 jpsall
```
## 3. 启动脚本
```shell
cd /home/wuss/bin
vim myhadoop.sh

#!/bin/bash
if [ $# -lt 1 ] 
then 
	echo "No Args Input..." 
	exit ; 
fi
case $1 in 
"start") 
	echo " =================== 启动 hadoop 集群 ===================" 
	echo " --------------- 启动 hdfs ---------------" 
	ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh" 
	echo " --------------- 启动 yarn ---------------"
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh" 
	echo " --------------- 启动 historyserver ---------------" 
	ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;
"restart") 
	echo " =================== 正在重启 hadoop 集群 !!! ==================="
	echo " =================== 关闭 hadoop 集群 ==================="
	echo " --------------- 关闭 historyserver ---------------"
	ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
	echo " --------------- 关闭 yarn ---------------" 
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh" 
	echo " --------------- 关闭 hdfs ---------------" 
	ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
	echo " =================== 启动 hadoop 集群 ===================" 
	echo " --------------- 启动 hdfs ---------------" 
	ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh" 
	echo " --------------- 启动 yarn ---------------"
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh" 
	echo " --------------- 启动 historyserver ---------------" 
	ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;
"stop")
	echo " =================== 关闭 hadoop 集群 ==================="
	echo " --------------- 关闭 historyserver ---------------"
	ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
	echo " --------------- 关闭 yarn ---------------" 
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh" 
	echo " --------------- 关闭 hdfs ---------------" 
	ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
;;
*)
	echo "Input Args Error..."
;;
esac


chmod 777 myhadoop.sh

xsync /home/wuss/bin
```
## 4. 上传及配置环境变量
```shell
cd /opt/software/
tar -zxvf /opt/software/hadoop-3.1.3.tar.gz -C /opt/module/
sudo vim /etc/profile.d/my_env.sh
```
写入
```shell
#HADOOP_HOME 
export HADOOP_HOME=/opt/module/hadoop-3.1.3 
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

source /etc/profile
hadoop version
```
## 5. 配置
```shell
cd /opt/module/hadoop-3.1.3/etc/hadoop/
```
### 5.1. 配置 core-site.xml
```shell
vim core-site.xml
```
```xml
<configuration>

   <!-- 指定NameNode的地址 -->

	<property>

		<name>fs.defaultFS</name>

		<value>hdfs://hadoop102:8020</value>

	</property>

	<!-- 指定hadoop数据的存储目录 -->

	<property>

		<name>hadoop.tmp.dir</name>

		<value>/opt/module/hadoop-3.1.3/data</value>

	</property>

	<!-- 配置HDFS网页登录使用的静态用户为wuss -->

	<property>

		<name>hadoop.http.staticuser.user</name>

		<value>wuss</value>

	</property>

	<!-- 配置该wuss(superUser)允许通过代理访问的主机节点 -->

	<property>

		<name>hadoop.proxyuser.wuss.hosts</name>

		<value>*</value>

	</property>

	<!-- 配置该wuss(superUser)允许通过代理用户所属组 -->

	<property>

		<name>hadoop.proxyuser.wuss.groups</name>

		<value>*</value>

	</property>

	<!-- 配置该wuss(superUser)允许通过代理的用户-->

	<property>

		<name>hadoop.proxyuser.wuss.groups</name>

		<value>*</value>

	</property>
	
</configuration>

```
### 5.2. 配置 hdfs-site.xml
```shell
vim hdfs-site.xml
```
```xml
<configuration>

	<!-- nn web 端访问地址-->
	<property>
		<name>dfs.namenode.http-address</name>
				<!-- hadoop102是主机名 -->
		<value>hadoop102:9870</value>
	</property>
	
	<!-- 2nn web 端访问地址-->
	<property>
		<name>dfs.namenode.secondary.http-address</name>
				<!-- hadoop104是主机名 -->
		<value>hadoop104:9868</value>
	</property>
	
</configuration>

```
### 5.3. 配置 yarn-site.xml
```shell
vim yarn-site.xml
```
```xml
<configuration>
	<!-- 指定 MR 走 shuffle -->
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>

	<!-- 指定 ResourceManager 的地址-->
	<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>hadoop103</value>
	</property>


	<!-- 开启日志聚集功能 -->

	<property>

		<name>yarn.log-aggregation-enable</name>

		<value>true</value>

	</property>

	<!-- 设置日志聚集服务器地址 -->

	<property> 

		<name>yarn.log.server.url</name> 

		<value>http://hadoop102:19888/jobhistory/logs</value>

	</property>

	<!-- 设置日志保留时间为7天 -->

	<property>

		<name>yarn.log-aggregation.retain-seconds</name>

		<value>604800</value>
	</property>
	
</configuration>

```
### 5.4. 配置 mapred-site.xml
```shell
vim mapred-site.xml
```
```xml
<configuration>

	<!-- 指定 MapReduce 程序运行在 Yarn 上 -->
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	<property>
      <name>yarn.app.mapreduce.am.env</name>
      <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    
    <property>
      <name>mapreduce.map.env</name>
      <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    
    <property>
      <name>mapreduce.reduce.env</name>
      <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
	
		<!-- 历史服务器端地址 -->
	<property>
		<name>mapreduce.jobhistory.address</name>
		<value>hadoop102:10020</value>
	</property>
	
	<!-- 历史服务器 web 端地址 -->
	<property>
		<name>mapreduce.jobhistory.webapp.address</name>
		<value>hadoop102:19888</value>
	</property>

</configuration>

```
### 5.5. 配置workers
```shell
vim workers
hadoop102
hadoop103
hadoop104
```
## 6. 分发
```shell
cd /opt/module
#注意用户是否设置了免密
xsync hadoop-3.1.3
sudo /home/wuss/bin/xsync /etc/profile.d/my_env.sh  
xcall.sh hadoop version
```
## 7. 第一次启动
删除data和log
`hdfs namenode -format`
## 8. 测试yran
```shell
myhadoop.sh start
cd /opt/module/hadoop-3.1.3/share/hadoop/mapreduce
hadoop jar hadoop-mapreduce-examples-3.1.3.jar pi 5 10
```